{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f3d402",
   "metadata": {},
   "source": [
    "\n",
    " # NOTEBOOK 1: DATA LOADING & EXPLORATION                      \n",
    " # Movie Recommender System                                    \n",
    "# Author: Mohamed Hedi Foughai                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c308065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🎬 MOVIE RECOMMENDER SYSTEM - DATA LOADING & EXPLORATION\n",
      "================================================================================\n",
      "📅 Started at: 2025-10-18 18:03:08\n",
      "🐍 Python version: 2.3.3\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)  # 2 decimal places\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)  # Default figure size\n",
    "\n",
    "# Print header\n",
    "print(\"=\" * 80)\n",
    "print(\"🎬 MOVIE RECOMMENDER SYSTEM - DATA LOADING & EXPLORATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"📅 Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"🐍 Python version: {pd.__version__}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf370c9f",
   "metadata": {},
   "source": [
    "## 1- SETUP PATHS & VERIFY DATA FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c3d0357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 DIRECTORY PATHS:\n",
      "--------------------------------------------------------------------------------\n",
      "Current directory:  c:\\Users\\mhfou\\Documents\\MovieRecommenderSystem\\notebooks\n",
      "Project root:       c:\\Users\\mhfou\\Documents\\MovieRecommenderSystem\n",
      "Raw data:           c:\\Users\\mhfou\\Documents\\MovieRecommenderSystem\\data\\raw\n",
      "Processed data:     c:\\Users\\mhfou\\Documents\\MovieRecommenderSystem\\data\\processed\n",
      "Models:             c:\\Users\\mhfou\\Documents\\MovieRecommenderSystem\\models\n",
      "Reports:            c:\\Users\\mhfou\\Documents\\MovieRecommenderSystem\\reports\\figures\n",
      "\n",
      "✅ Directories created/verified\n",
      "\n",
      "================================================================================\n",
      "📂 CHECKING DATA FILES\n",
      "================================================================================\n",
      "   ✓ ratings.csv          (   646.8 MB) ✅\n",
      "   ✓ movies.csv           (     2.9 MB) ✅\n",
      "   ✓ tags.csv             (    37.0 MB) ✅\n",
      "   ✓ links.csv            (     1.3 MB) ✅\n",
      "\n",
      "📋 Optional files:\n",
      "   ✓ genome-scores.csv    (   415.0 MB)\n",
      "   ✓ genome-tags.csv      (     0.0 MB)\n",
      "   ✓ README.txt           (     0.0 MB)\n",
      "\n",
      "================================================================================\n",
      "✅ ALL REQUIRED DATA FILES FOUND! Ready to load data! 🎉\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Get directory paths\n",
    "# We're currently in: MovieRecommenderSystem/notebooks/\n",
    "# We need to go up one level to access data/\n",
    "BASE_DIR = os.path.dirname(os.getcwd())  # Go up from notebooks/ to project root\n",
    "RAW_DIR = os.path.join(BASE_DIR, 'data', 'raw')\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, 'models')\n",
    "REPORTS_DIR = os.path.join(BASE_DIR, 'reports', 'figures')\n",
    "\n",
    "print(\"\\n📁 DIRECTORY PATHS:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Current directory:  {os.getcwd()}\")\n",
    "print(f\"Project root:       {BASE_DIR}\")\n",
    "print(f\"Raw data:           {RAW_DIR}\")\n",
    "print(f\"Processed data:     {PROCESSED_DIR}\")\n",
    "print(f\"Models:             {MODELS_DIR}\")\n",
    "print(f\"Reports:            {REPORTS_DIR}\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"\\n✅ Directories created/verified\")\n",
    "\n",
    "# Check for required data files\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📂 CHECKING DATA FILES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "required_files = [\n",
    "    'ratings.csv',\n",
    "    'movies.csv', \n",
    "    'tags.csv',\n",
    "    'links.csv'\n",
    "]\n",
    "\n",
    "all_files_present = True\n",
    "\n",
    "for file in required_files:\n",
    "    filepath = os.path.join(RAW_DIR, file)\n",
    "    if os.path.exists(filepath):\n",
    "        size_mb = os.path.getsize(filepath) / (1024**2)  # Convert bytes to MB\n",
    "        print(f\"   ✓ {file:20s} ({size_mb:>8.1f} MB) ✅\")\n",
    "    else:\n",
    "        print(f\"   ✗ {file:20s} - NOT FOUND! ❌\")\n",
    "        all_files_present = False\n",
    "\n",
    "# Check optional files\n",
    "print(\"\\n📋 Optional files:\")\n",
    "optional_files = ['genome-scores.csv', 'genome-tags.csv', 'README.txt']\n",
    "\n",
    "for file in optional_files:\n",
    "    filepath = os.path.join(RAW_DIR, file)\n",
    "    if os.path.exists(filepath):\n",
    "        size_mb = os.path.getsize(filepath) / (1024**2)\n",
    "        print(f\"   ✓ {file:20s} ({size_mb:>8.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"   - {file:20s} (not present)\")\n",
    "\n",
    "# Final check\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "if all_files_present:\n",
    "    print(\"✅ ALL REQUIRED DATA FILES FOUND! Ready to load data! 🎉\")\n",
    "else:\n",
    "    print(\"❌ MISSING FILES! Please check your data/raw/ folder.\")\n",
    "    print(\"   Download from: https://grouplens.org/datasets/movielens/25m/\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774348b4",
   "metadata": {},
   "source": [
    "## 2- LOAD MOVIELENS 25M DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10df82b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "📂 LOADING MOVIELENS 25M DATASET\n",
      "================================================================================\n",
      "\n",
      "⏳ Loading files (this may take 1-2 minutes)...\n",
      "✅ All files loaded successfully in 14.6 seconds!\n",
      "\n",
      "📊 Dataset Shapes:\n",
      "   • Ratings:   25,000,095 rows ×  4 columns\n",
      "   • Movies:        62,423 rows ×  3 columns\n",
      "   • Tags:       1,093,360 rows ×  4 columns\n",
      "   • Links:         62,423 rows ×  3 columns\n",
      "\n",
      "💾 Total Memory Usage: 860.3 MB\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📂 LOADING MOVIELENS 25M DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n⏳ Loading files (this may take 1-2 minutes)...\")\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Load main datasets\n",
    "ratings = pd.read_csv(os.path.join(RAW_DIR, 'ratings.csv'))\n",
    "movies = pd.read_csv(os.path.join(RAW_DIR, 'movies.csv'))\n",
    "tags = pd.read_csv(os.path.join(RAW_DIR, 'tags.csv'))\n",
    "links = pd.read_csv(os.path.join(RAW_DIR, 'links.csv'))\n",
    "\n",
    "end_time = datetime.now()\n",
    "load_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(f\"✅ All files loaded successfully in {load_time:.1f} seconds!\")\n",
    "\n",
    "print(f\"\\n📊 Dataset Shapes:\")\n",
    "print(f\"   • Ratings: {ratings.shape[0]:>12,} rows × {ratings.shape[1]:>2} columns\")\n",
    "print(f\"   • Movies:  {movies.shape[0]:>12,} rows × {movies.shape[1]:>2} columns\")\n",
    "print(f\"   • Tags:    {tags.shape[0]:>12,} rows × {tags.shape[1]:>2} columns\")\n",
    "print(f\"   • Links:   {links.shape[0]:>12,} rows × {links.shape[1]:>2} columns\")\n",
    "\n",
    "print(f\"\\n💾 Total Memory Usage: {(ratings.memory_usage(deep=True).sum() + movies.memory_usage(deep=True).sum() + tags.memory_usage(deep=True).sum() + links.memory_usage(deep=True).sum()) / (1024**2):.1f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe04cb5",
   "metadata": {},
   "source": [
    "## 3- DATA STRUCTURE INSPECTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32fe5abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🔍 DATA STRUCTURE INSPECTION\n",
      "================================================================================\n",
      "\n",
      "📋 RATINGS Dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "   userId  movieId  rating   timestamp\n",
      "0       1      296    5.00  1147880044\n",
      "1       1      306    3.50  1147868817\n",
      "2       1      307    5.00  1147868828\n",
      "3       1      665    5.00  1147878820\n",
      "4       1      899    3.50  1147868510\n",
      "5       1     1088    4.00  1147868495\n",
      "6       1     1175    3.50  1147868826\n",
      "7       1     1217    3.50  1147878326\n",
      "8       1     1237    5.00  1147868839\n",
      "9       1     1250    4.00  1147868414\n",
      "\n",
      "Columns: ['userId', 'movieId', 'rating', 'timestamp']\n",
      "\n",
      "Data types:\n",
      "userId         int64\n",
      "movieId        int64\n",
      "rating       float64\n",
      "timestamp      int64\n",
      "dtype: object\n",
      "\n",
      "Memory usage: 762.94 MB\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "📋 MOVIES Dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "5        6                         Heat (1995)   \n",
      "6        7                      Sabrina (1995)   \n",
      "7        8                 Tom and Huck (1995)   \n",
      "8        9                 Sudden Death (1995)   \n",
      "9       10                    GoldenEye (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "5                        Action|Crime|Thriller  \n",
      "6                               Comedy|Romance  \n",
      "7                           Adventure|Children  \n",
      "8                                       Action  \n",
      "9                    Action|Adventure|Thriller  \n",
      "\n",
      "Columns: ['movieId', 'title', 'genres']\n",
      "\n",
      "Data types:\n",
      "movieId     int64\n",
      "title      object\n",
      "genres     object\n",
      "dtype: object\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "📋 TAGS Dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "    userId  movieId                      tag   timestamp\n",
      "0        3      260                  classic  1439472355\n",
      "1        3      260                   sci-fi  1439472256\n",
      "2        4     1732              dark comedy  1573943598\n",
      "3        4     1732           great dialogue  1573943604\n",
      "4        4     7569         so bad it's good  1573943455\n",
      "5        4    44665     unreliable narrators  1573943619\n",
      "6        4   115569                    tense  1573943077\n",
      "7        4   115713  artificial intelligence  1573942979\n",
      "8        4   115713            philosophical  1573943033\n",
      "9        4   115713                    tense  1573943042\n",
      "10       4   148426         so bad it's good  1573942965\n",
      "11       4   164909                   cliche  1573943721\n",
      "12       4   164909                  musical  1573943714\n",
      "13       4   168250                   horror  1573945163\n",
      "14       4   168250            unpredictable  1573945171\n",
      "\n",
      "Columns: ['userId', 'movieId', 'tag', 'timestamp']\n",
      "\n",
      "Data types:\n",
      "userId        int64\n",
      "movieId       int64\n",
      "tag          object\n",
      "timestamp     int64\n",
      "dtype: object\n",
      "\n",
      "💡 These user-generated tags will be used for NLP analysis!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "📋 LINKS Dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "   movieId  imdbId   tmdbId\n",
      "0        1  114709   862.00\n",
      "1        2  113497  8844.00\n",
      "2        3  113228 15602.00\n",
      "3        4  114885 31357.00\n",
      "4        5  113041 11862.00\n",
      "5        6  113277   949.00\n",
      "6        7  114319 11860.00\n",
      "7        8  112302 45325.00\n",
      "8        9  114576  9091.00\n",
      "9       10  113189   710.00\n",
      "\n",
      "Columns: ['movieId', 'imdbId', 'tmdbId']\n",
      "\n",
      "💡 Links to IMDB and TMDB - useful for getting movie metadata\n",
      "\n",
      "================================================================================\n",
      "📊 GENOME DATA (Optional - Machine-Generated Tags)\n",
      "================================================================================\n",
      "\n",
      "⏳ Loading genome data (this may take a minute)...\n",
      "\n",
      "📋 GENOME SCORES Dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "   movieId  tagId  relevance\n",
      "0        1      1       0.03\n",
      "1        1      2       0.02\n",
      "2        1      3       0.06\n",
      "3        1      4       0.08\n",
      "4        1      5       0.14\n",
      "5        1      6       0.15\n",
      "6        1      7       0.06\n",
      "7        1      8       0.20\n",
      "8        1      9       0.20\n",
      "9        1     10       0.03\n",
      "\n",
      "Shape: 15,584,448 rows × 3 columns\n",
      "Columns: ['movieId', 'tagId', 'relevance']\n",
      "\n",
      "💡 Relevance scores (0-1) of tags for each movie\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "📋 GENOME TAGS Dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "    tagId              tag\n",
      "0       1              007\n",
      "1       2     007 (series)\n",
      "2       3     18th century\n",
      "3       4            1920s\n",
      "4       5            1930s\n",
      "5       6            1950s\n",
      "6       7            1960s\n",
      "7       8            1970s\n",
      "8       9            1980s\n",
      "9      10     19th century\n",
      "10     11               3d\n",
      "11     12             70mm\n",
      "12     13              80s\n",
      "13     14             9/11\n",
      "14     15          aardman\n",
      "15     16  aardman studios\n",
      "16     17         abortion\n",
      "17     18           absurd\n",
      "18     19           action\n",
      "19     20    action packed\n",
      "\n",
      "Shape: 1,128 rows × 2 columns\n",
      "Columns: ['tagId', 'tag']\n",
      "\n",
      "💡 1128 machine-generated tags for content analysis\n",
      "\n",
      "📊 Genome data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 4: DATA STRUCTURE INSPECTION\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🔍 DATA STRUCTURE INSPECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n📋 RATINGS Dataset:\")\n",
    "print(\"-\" * 80)\n",
    "print(ratings.head(10))\n",
    "print(f\"\\nColumns: {ratings.columns.tolist()}\")\n",
    "print(f\"\\nData types:\\n{ratings.dtypes}\")\n",
    "print(f\"\\nMemory usage: {ratings.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"📋 MOVIES Dataset:\")\n",
    "print(\"-\" * 80)\n",
    "print(movies.head(10))\n",
    "print(f\"\\nColumns: {movies.columns.tolist()}\")\n",
    "print(f\"\\nData types:\\n{movies.dtypes}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"📋 TAGS Dataset:\")\n",
    "print(\"-\" * 80)\n",
    "print(tags.head(15))\n",
    "print(f\"\\nColumns: {tags.columns.tolist()}\")\n",
    "print(f\"\\nData types:\\n{tags.dtypes}\")\n",
    "print(f\"\\n💡 These user-generated tags will be used for NLP analysis!\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"📋 LINKS Dataset:\")\n",
    "print(\"-\" * 80)\n",
    "print(links.head(10))\n",
    "print(f\"\\nColumns: {links.columns.tolist()}\")\n",
    "print(f\"\\n💡 Links to IMDB and TMDB - useful for getting movie metadata\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📊 GENOME DATA (Optional - Machine-Generated Tags)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "genome_scores_path = os.path.join(RAW_DIR, 'genome-scores.csv')\n",
    "genome_tags_path = os.path.join(RAW_DIR, 'genome-tags.csv')\n",
    "\n",
    "if os.path.exists(genome_scores_path) and os.path.exists(genome_tags_path):\n",
    "    print(\"\\n⏳ Loading genome data (this may take a minute)...\")\n",
    "    \n",
    "    genome_scores = pd.read_csv(genome_scores_path)\n",
    "    genome_tags = pd.read_csv(genome_tags_path)\n",
    "    \n",
    "    print(\"\\n📋 GENOME SCORES Dataset:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(genome_scores.head(10))\n",
    "    print(f\"\\nShape: {genome_scores.shape[0]:,} rows × {genome_scores.shape[1]} columns\")\n",
    "    print(f\"Columns: {genome_scores.columns.tolist()}\")\n",
    "    print(f\"\\n💡 Relevance scores (0-1) of tags for each movie\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"📋 GENOME TAGS Dataset:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(genome_tags.head(20))\n",
    "    print(f\"\\nShape: {genome_tags.shape[0]:,} rows × {genome_tags.shape[1]} columns\")\n",
    "    print(f\"Columns: {genome_tags.columns.tolist()}\")\n",
    "    print(f\"\\n💡 {genome_tags.shape[0]} machine-generated tags for content analysis\")\n",
    "    \n",
    "    print(f\"\\n📊 Genome data loaded successfully!\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Genome data files not found (optional)\")\n",
    "    genome_scores = None\n",
    "    genome_tags = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6468df4",
   "metadata": {},
   "source": [
    "## 4- DATASET STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63ce9a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "📊 DATASET STATISTICS\n",
      "================================================================================\n",
      "\n",
      "🎬 Ratings Overview:\n",
      "   • Total ratings:          25,000,095\n",
      "   • Unique users:              162,541\n",
      "   • Unique movies:              59,047\n",
      "   • Rating range:         0.5 - 5.0\n",
      "   • Average rating:               3.53\n",
      "   • Median rating:                3.50\n",
      "   • Std deviation:                1.06\n",
      "\n",
      "📈 Rating Distribution:\n",
      "   0.5 ⭐: ███                                        1.6% (   393,068)\n",
      "   1.0 ⭐: ██████                                     3.1% (   776,815)\n",
      "   1.5 ⭐: ███                                        1.6% (   399,490)\n",
      "   2.0 ⭐: █████████████                              6.6% ( 1,640,868)\n",
      "   2.5 ⭐: ██████████                                 5.1% ( 1,262,797)\n",
      "   3.0 ⭐: ███████████████████████████████████████   19.6% ( 4,896,928)\n",
      "   3.5 ⭐: █████████████████████████                 12.7% ( 3,177,318)\n",
      "   4.0 ⭐: █████████████████████████████████████████████████████  26.6% ( 6,639,798)\n",
      "   4.5 ⭐: █████████████████                          8.8% ( 2,200,539)\n",
      "   5.0 ⭐: ████████████████████████████              14.4% ( 3,612,474)\n",
      "\n",
      "👥 User Activity:\n",
      "   • Avg ratings per user:        153.8\n",
      "   • Median:                       71.0\n",
      "   • Most active user:           32,202 ratings\n",
      "   • Least active user:              20 rating(s)\n",
      "\n",
      "   Quartiles:\n",
      "   • 25th percentile:                36 ratings\n",
      "   • 50th percentile:                71 ratings\n",
      "   • 75th percentile:               162 ratings\n",
      "\n",
      "🎥 Movie Popularity:\n",
      "   • Avg ratings per movie:       423.4\n",
      "   • Median:                        6.0\n",
      "   • Most popular movie:         81,491 ratings\n",
      "   • Movies with 1 rating:       10,298\n",
      "   • Movies with <5 ratings:     26,327\n",
      "   • Movies with >1000:           3,790\n",
      "\n",
      "   Quartiles:\n",
      "   • 25th percentile:                 2 ratings\n",
      "   • 50th percentile:                 6 ratings\n",
      "   • 75th percentile:                36 ratings\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📊 DATASET STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "n_ratings = len(ratings)\n",
    "n_users = ratings['userId'].nunique()\n",
    "n_movies = ratings['movieId'].nunique()\n",
    "\n",
    "print(\"\\n🎬 Ratings Overview:\")\n",
    "print(f\"   • Total ratings:        {n_ratings:>12,}\")\n",
    "print(f\"   • Unique users:         {n_users:>12,}\")\n",
    "print(f\"   • Unique movies:        {n_movies:>12,}\")\n",
    "print(f\"   • Rating range:         {ratings['rating'].min():.1f} - {ratings['rating'].max():.1f}\")\n",
    "print(f\"   • Average rating:       {ratings['rating'].mean():>12.2f}\")\n",
    "print(f\"   • Median rating:        {ratings['rating'].median():>12.2f}\")\n",
    "print(f\"   • Std deviation:        {ratings['rating'].std():>12.2f}\")\n",
    "\n",
    "print(\"\\n📈 Rating Distribution:\")\n",
    "rating_dist = ratings['rating'].value_counts().sort_index()\n",
    "for rating, count in rating_dist.items():\n",
    "    percentage = (count / n_ratings) * 100\n",
    "    bar_length = int(percentage * 2)\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"   {rating:.1f} ⭐: {bar:<40} {percentage:>5.1f}% ({count:>10,})\")\n",
    "\n",
    "print(\"\\n👥 User Activity:\")\n",
    "user_counts = ratings.groupby('userId').size()\n",
    "print(f\"   • Avg ratings per user: {user_counts.mean():>12.1f}\")\n",
    "print(f\"   • Median:               {user_counts.median():>12.1f}\")\n",
    "print(f\"   • Most active user:     {user_counts.max():>12,} ratings\")\n",
    "print(f\"   • Least active user:    {user_counts.min():>12} rating(s)\")\n",
    "\n",
    "user_activity_quartiles = user_counts.quantile([0.25, 0.5, 0.75])\n",
    "print(f\"\\n   Quartiles:\")\n",
    "print(f\"   • 25th percentile:      {user_activity_quartiles[0.25]:>12.0f} ratings\")\n",
    "print(f\"   • 50th percentile:      {user_activity_quartiles[0.5]:>12.0f} ratings\")\n",
    "print(f\"   • 75th percentile:      {user_activity_quartiles[0.75]:>12.0f} ratings\")\n",
    "\n",
    "print(\"\\n🎥 Movie Popularity:\")\n",
    "movie_counts = ratings.groupby('movieId').size()\n",
    "print(f\"   • Avg ratings per movie: {movie_counts.mean():>11.1f}\")\n",
    "print(f\"   • Median:                {movie_counts.median():>11.1f}\")\n",
    "print(f\"   • Most popular movie:    {movie_counts.max():>11,} ratings\")\n",
    "print(f\"   • Movies with 1 rating:  {(movie_counts == 1).sum():>11,}\")\n",
    "print(f\"   • Movies with <5 ratings: {(movie_counts < 5).sum():>10,}\")\n",
    "print(f\"   • Movies with >1000:     {(movie_counts > 1000).sum():>11,}\")\n",
    "\n",
    "movie_popularity_quartiles = movie_counts.quantile([0.25, 0.5, 0.75])\n",
    "print(f\"\\n   Quartiles:\")\n",
    "print(f\"   • 25th percentile:      {movie_popularity_quartiles[0.25]:>12.0f} ratings\")\n",
    "print(f\"   • 50th percentile:      {movie_popularity_quartiles[0.5]:>12.0f} ratings\")\n",
    "print(f\"   • 75th percentile:      {movie_popularity_quartiles[0.75]:>12.0f} ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2402f97",
   "metadata": {},
   "source": [
    " ## 5- TAGS ANALYSIS - NLP DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52324086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🏷️  TAGS ANALYSIS - NLP DATA\n",
      "================================================================================\n",
      "\n",
      "📊 Tags Overview:\n",
      "   • Total tag entries:        1,093,360\n",
      "   • Unique tags:                 73,050\n",
      "   • Movies with tags:            45,251\n",
      "   • Users who tagged:            14,592\n",
      "   • Avg tags per movie:            24.2\n",
      "\n",
      "🔥 Most Common Tags (Top 30):\n",
      "    1. sci-fi                              ██████████████████████████████  8,330\n",
      "    2. atmospheric                         ███████████████████████         6,516\n",
      "    3. action                              █████████████████████           5,907\n",
      "    4. comedy                              ████████████████████            5,702\n",
      "    5. surreal                             ███████████████████             5,326\n",
      "    6. based on a book                     ██████████████████              5,079\n",
      "    7. twist ending                        █████████████████               4,820\n",
      "    8. funny                               █████████████████               4,738\n",
      "    9. visually appealing                  ████████████████                4,526\n",
      "   10. dystopia                            ███████████████                 4,257\n",
      "   11. dark comedy                         ██████████████                  4,026\n",
      "   12. BD-R                                ██████████████                  3,966\n",
      "   13. thought-provoking                   █████████████                   3,844\n",
      "   14. romance                             █████████████                   3,791\n",
      "   15. stylized                            █████████████                   3,728\n",
      "   16. quirky                              █████████████                   3,677\n",
      "   17. psychology                          █████████████                   3,625\n",
      "   18. woman director                      ████████████                    3,589\n",
      "   19. fantasy                             ████████████                    3,523\n",
      "   20. classic                             ████████████                    3,456\n",
      "   21. violence                            ███████████                     3,316\n",
      "   22. time travel                         ███████████                     3,248\n",
      "   23. murder                              ███████████                     3,240\n",
      "   24. social commentary                   ███████████                     3,197\n",
      "   25. thriller                            ██████████                      2,990\n",
      "   26. superhero                           ██████████                      2,931\n",
      "   27. cinematography                      ██████████                      2,925\n",
      "   28. revenge                             ██████████                      2,923\n",
      "   29. dark                                ██████████                      2,919\n",
      "   30. space                               ██████████                      2,894\n",
      "\n",
      "💡 Sample Tags for Popular Movies:\n",
      "\n",
      "   🎬 Star Wars: Episode IV - A New Hope (1977)\n",
      "      Tags: classic, sci-fi, action, adventure, fantasy, space adventure, classic sci-fi, good vs evil\n",
      "\n",
      "   🎬 Pulp Fiction (1994)\n",
      "      Tags: assassin, Black comedy, cult film, dark comedy, Quentin Tarantino, stylized, violence, Acting\n",
      "\n",
      "   🎬 Inception (2010)\n",
      "      Tags: sci-fi, action, alternate reality, drama, psychology, thought-provoking, twist ending, action\n",
      "\n",
      "   🎬 Interstellar (2014)\n",
      "      Tags: good science, Hans Zimmer, philosophical issues, sci-fi, science fiction, space, space travel, time-travel\n",
      "\n",
      "   🎬 Fight Club (1999)\n",
      "      Tags: complicated, mindfuck, violence, atmospheric, dark comedy, disturbing, mental illness, mindfuck\n",
      "\n",
      "📈 Tag Distribution:\n",
      "   • Min tags per movie:               1\n",
      "   • Max tags per movie:           6,180\n",
      "   • Median tags per movie:            5\n",
      "   • Mean tags per movie:           24.2\n",
      "\n",
      "   • Min tags per user:                1\n",
      "   • Max tags per user:          183,356\n",
      "   • Median tags per user:             5\n",
      "   • Mean tags per user:            74.9\n",
      "\n",
      "✅ Tags Data Quality:\n",
      "   • Missing values:                  16\n",
      "   • Empty strings:                    9\n",
      "   • Average tag length:            10.7 characters\n",
      "   • Shortest tag:                   1.0 characters\n",
      "   • Longest tag:                  234.0 characters\n",
      "\n",
      "💡 Tag Length Distribution:\n",
      "   (0, 5]         : █████████████████████████                 12.8% ( 139,855)\n",
      "   (5, 10]        : █████████████████████████████████████████████████████████████████████████████████████  42.6% ( 466,032)\n",
      "   (10, 15]       : ███████████████████████████████████████████████████████████  29.6% ( 323,725)\n",
      "   (15, 20]       : █████████████████████                     10.8% ( 118,301)\n",
      "   (20, 30]       : ██████                                     3.5% (  38,015)\n",
      "   (30, 50]       : █                                          0.6% (   6,518)\n",
      "   (50, 100]      :                                            0.1% (     807)\n",
      "   (100, 500]     :                                            0.0% (      91)\n",
      "\n",
      "================================================================================\n",
      "✅ Tags are ready for NLP processing!\n",
      "   • We'll use TF-IDF to extract semantic features\n",
      "   • These tags will improve content-based recommendations\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🏷️  TAGS ANALYSIS - NLP DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "n_tags = len(tags)\n",
    "n_unique_tags = tags['tag'].nunique()\n",
    "n_movies_with_tags = tags['movieId'].nunique()\n",
    "n_users_tagging = tags['userId'].nunique()\n",
    "\n",
    "print(f\"\\n📊 Tags Overview:\")\n",
    "print(f\"   • Total tag entries:     {n_tags:>12,}\")\n",
    "print(f\"   • Unique tags:           {n_unique_tags:>12,}\")\n",
    "print(f\"   • Movies with tags:      {n_movies_with_tags:>12,}\")\n",
    "print(f\"   • Users who tagged:      {n_users_tagging:>12,}\")\n",
    "print(f\"   • Avg tags per movie:    {n_tags / n_movies_with_tags:>12.1f}\")\n",
    "\n",
    "print(\"\\n🔥 Most Common Tags (Top 30):\")\n",
    "top_tags = tags['tag'].value_counts().head(30)\n",
    "for i, (tag, count) in enumerate(top_tags.items(), 1):\n",
    "    bar_length = int((count / top_tags.iloc[0]) * 30)\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"   {i:2d}. {tag:35s} {bar:<30} {count:>6,}\")\n",
    "\n",
    "print(\"\\n💡 Sample Tags for Popular Movies:\")\n",
    "popular_movies_with_tags = tags.groupby('movieId').size().sort_values(ascending=False).head(5)\n",
    "\n",
    "for movie_id in popular_movies_with_tags.index:\n",
    "    movie_title = movies[movies['movieId'] == movie_id]['title'].values[0]\n",
    "    movie_tags = tags[tags['movieId'] == movie_id]['tag'].values[:8]\n",
    "    print(f\"\\n   🎬 {movie_title}\")\n",
    "    print(f\"      Tags: {', '.join(movie_tags)}\")\n",
    "\n",
    "print(\"\\n📈 Tag Distribution:\")\n",
    "tags_per_movie = tags.groupby('movieId').size()\n",
    "print(f\"   • Min tags per movie:    {tags_per_movie.min():>12}\")\n",
    "print(f\"   • Max tags per movie:    {tags_per_movie.max():>12,}\")\n",
    "print(f\"   • Median tags per movie: {tags_per_movie.median():>12.0f}\")\n",
    "print(f\"   • Mean tags per movie:   {tags_per_movie.mean():>12.1f}\")\n",
    "\n",
    "tags_per_user = tags.groupby('userId').size()\n",
    "print(f\"\\n   • Min tags per user:     {tags_per_user.min():>12}\")\n",
    "print(f\"   • Max tags per user:     {tags_per_user.max():>12,}\")\n",
    "print(f\"   • Median tags per user:  {tags_per_user.median():>12.0f}\")\n",
    "print(f\"   • Mean tags per user:    {tags_per_user.mean():>12.1f}\")\n",
    "\n",
    "print(\"\\n✅ Tags Data Quality:\")\n",
    "print(f\"   • Missing values:        {tags.isnull().sum().sum():>12}\")\n",
    "print(f\"   • Empty strings:         {(tags['tag'].str.strip() == '').sum():>12}\")\n",
    "print(f\"   • Average tag length:    {tags['tag'].str.len().mean():>12.1f} characters\")\n",
    "print(f\"   • Shortest tag:          {tags['tag'].str.len().min():>12} characters\")\n",
    "print(f\"   • Longest tag:           {tags['tag'].str.len().max():>12} characters\")\n",
    "\n",
    "print(\"\\n💡 Tag Length Distribution:\")\n",
    "tag_lengths = tags['tag'].str.len()\n",
    "bins = [0, 5, 10, 15, 20, 30, 50, 100, 500]\n",
    "tag_length_dist = pd.cut(tag_lengths, bins=bins).value_counts().sort_index()\n",
    "for interval, count in tag_length_dist.items():\n",
    "    percentage = (count / len(tags)) * 100\n",
    "    bar_length = int(percentage * 2)\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"   {str(interval):15s}: {bar:<40} {percentage:>5.1f}% ({count:>8,})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ Tags are ready for NLP processing!\")\n",
    "print(\"   • We'll use TF-IDF to extract semantic features\")\n",
    "print(\"   • These tags will improve content-based recommendations\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de44a9",
   "metadata": {},
   "source": [
    "## 6- GENRE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3947724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🎭 GENRE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "📊 Genre Distribution:\n",
      "   Total unique genres: 20\n",
      "\n",
      "   Drama               : ████████████████████                      41.0% (25,606 movies)\n",
      "   Comedy              : █████████████                             27.0% (16,870 movies)\n",
      "   Thriller            : ██████                                    13.9% (8,654 movies)\n",
      "   Romance             : ██████                                    12.4% (7,719 movies)\n",
      "   Action              : █████                                     11.8% (7,348 movies)\n",
      "   Horror              : ████                                       9.6% (5,989 movies)\n",
      "   Documentary         : ████                                       9.0% (5,605 movies)\n",
      "   Crime               : ████                                       8.5% (5,319 movies)\n",
      "   (no genres listed)  : ████                                       8.1% (5,062 movies)\n",
      "   Adventure           : ███                                        6.6% (4,145 movies)\n",
      "   Sci-Fi              : ██                                         5.8% (3,595 movies)\n",
      "   Children            : ██                                         4.7% (2,935 movies)\n",
      "   Animation           : ██                                         4.7% (2,929 movies)\n",
      "   Mystery             : ██                                         4.7% (2,925 movies)\n",
      "   Fantasy             : ██                                         4.4% (2,731 movies)\n",
      "   War                 : █                                          3.0% (1,874 movies)\n",
      "   Western             : █                                          2.2% (1,399 movies)\n",
      "   Musical             :                                            1.7% (1,054 movies)\n",
      "   Film-Noir           :                                            0.6% (  353 movies)\n",
      "   IMAX                :                                            0.3% (  195 movies)\n",
      "\n",
      "📊 Genres per Movie:\n",
      "   • Average:  1.80\n",
      "   • Median:   2\n",
      "   • Max:      10\n",
      "   • Min:      1\n",
      "\n",
      "   Distribution:\n",
      "   1 genre(s):  █████████████████████████████████████████████████  49.1% (30,631 movies)\n",
      "   2 genre(s):  █████████████████████████████             29.4% (18,326 movies)\n",
      "   3 genre(s):  ███████████████                           15.8% (9,852 movies)\n",
      "   4 genre(s):  ████                                       4.5% (2,784 movies)\n",
      "   5 genre(s):  █                                          1.1% (  680 movies)\n",
      "   6 genre(s):                                             0.2% (  123 movies)\n",
      "   7 genre(s):                                             0.0% (   24 movies)\n",
      "   8 genre(s):                                             0.0% (    2 movies)\n",
      "   10 genre(s):                                             0.0% (    1 movies)\n",
      "\n",
      "🎬 Sample Movies with Genres:\n",
      "                                 title  \\\n",
      "0                     Toy Story (1995)   \n",
      "1                       Jumanji (1995)   \n",
      "2              Grumpier Old Men (1995)   \n",
      "3             Waiting to Exhale (1995)   \n",
      "4   Father of the Bride Part II (1995)   \n",
      "5                          Heat (1995)   \n",
      "6                       Sabrina (1995)   \n",
      "7                  Tom and Huck (1995)   \n",
      "8                  Sudden Death (1995)   \n",
      "9                     GoldenEye (1995)   \n",
      "10      American President, The (1995)   \n",
      "11  Dracula: Dead and Loving It (1995)   \n",
      "12                        Balto (1995)   \n",
      "13                        Nixon (1995)   \n",
      "14             Cutthroat Island (1995)   \n",
      "\n",
      "                                         genres  \n",
      "0   Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                    Adventure|Children|Fantasy  \n",
      "2                                Comedy|Romance  \n",
      "3                          Comedy|Drama|Romance  \n",
      "4                                        Comedy  \n",
      "5                         Action|Crime|Thriller  \n",
      "6                                Comedy|Romance  \n",
      "7                            Adventure|Children  \n",
      "8                                        Action  \n",
      "9                     Action|Adventure|Thriller  \n",
      "10                         Comedy|Drama|Romance  \n",
      "11                                Comedy|Horror  \n",
      "12                 Adventure|Animation|Children  \n",
      "13                                        Drama  \n",
      "14                     Action|Adventure|Romance  \n",
      "\n",
      "📊 Most Common Genre Combinations:\n",
      "    1. Drama                                              (9,056 movies)\n",
      "    2. Comedy                                             (5,674 movies)\n",
      "    3. (no genres listed)                                 (5,062 movies)\n",
      "    4. Documentary                                        (4,731 movies)\n",
      "    5. Comedy|Drama                                       (2,386 movies)\n",
      "    6. Drama|Romance                                      (2,126 movies)\n",
      "    7. Horror                                             (1,661 movies)\n",
      "    8. Comedy|Romance                                     (1,577 movies)\n",
      "    9. Comedy|Drama|Romance                               (1,044 movies)\n",
      "   10. Drama|Thriller                                     ( 933 movies)\n",
      "   11. Thriller                                           ( 919 movies)\n",
      "   12. Crime|Drama                                        ( 903 movies)\n",
      "   13. Horror|Thriller                                    ( 851 movies)\n",
      "   14. Animation                                          ( 729 movies)\n",
      "   15. Drama|War                                          ( 653 movies)\n",
      "\n",
      "💡 Genre Co-occurrence Analysis:\n",
      "\n",
      "   Top 20 Genre Pairs:\n",
      "    1. Drama           + Romance         : 4,654 movies\n",
      "    2. Comedy          + Drama           : 4,603 movies\n",
      "    3. Drama           + Thriller        : 3,510 movies\n",
      "    4. Comedy          + Romance         : 3,450 movies\n",
      "    5. Crime           + Drama           : 2,996 movies\n",
      "    6. Action          + Drama           : 2,406 movies\n",
      "    7. Action          + Thriller        : 2,209 movies\n",
      "    8. Horror          + Thriller        : 2,181 movies\n",
      "    9. Crime           + Thriller        : 2,065 movies\n",
      "   10. Action          + Adventure       : 1,652 movies\n",
      "   11. Mystery         + Thriller        : 1,466 movies\n",
      "   12. Action          + Crime           : 1,423 movies\n",
      "   13. Drama           + War             : 1,348 movies\n",
      "   14. Action          + Comedy          : 1,333 movies\n",
      "   15. Drama           + Mystery         : 1,292 movies\n",
      "   16. Action          + Sci-Fi          : 1,185 movies\n",
      "   17. Children        + Comedy          : 1,169 movies\n",
      "   18. Adventure       + Drama           : 1,138 movies\n",
      "   19. Comedy          + Crime           : 1,044 movies\n",
      "   20. Animation       + Children        : 1,015 movies\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🎭 GENRE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "movies['genres_list'] = movies['genres'].str.split('|')\n",
    "\n",
    "from collections import Counter\n",
    "all_genres = []\n",
    "for genres in movies['genres_list'].dropna():\n",
    "    all_genres.extend(genres)\n",
    "\n",
    "genre_counts = Counter(all_genres)\n",
    "\n",
    "print(f\"\\n📊 Genre Distribution:\")\n",
    "print(f\"   Total unique genres: {len(genre_counts)}\")\n",
    "print()\n",
    "\n",
    "for genre, count in sorted(genre_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    percentage = (count / len(movies)) * 100\n",
    "    bar_length = int(percentage / 2)\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"   {genre:20s}: {bar:<40} {percentage:5.1f}% ({count:>5,} movies)\")\n",
    "\n",
    "movies['genre_count'] = movies['genres_list'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "print(f\"\\n📊 Genres per Movie:\")\n",
    "print(f\"   • Average:  {movies['genre_count'].mean():.2f}\")\n",
    "print(f\"   • Median:   {movies['genre_count'].median():.0f}\")\n",
    "print(f\"   • Max:      {movies['genre_count'].max()}\")\n",
    "print(f\"   • Min:      {movies['genre_count'].min()}\")\n",
    "\n",
    "genre_count_dist = movies['genre_count'].value_counts().sort_index()\n",
    "print(f\"\\n   Distribution:\")\n",
    "for n_genres, count in genre_count_dist.items():\n",
    "    percentage = (count / len(movies)) * 100\n",
    "    bar_length = int(percentage)\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"   {n_genres} genre(s):  {bar:<40} {percentage:5.1f}% ({count:>5,} movies)\")\n",
    "\n",
    "print(\"\\n🎬 Sample Movies with Genres:\")\n",
    "print(movies[['title', 'genres']].head(15))\n",
    "\n",
    "print(\"\\n📊 Most Common Genre Combinations:\")\n",
    "genre_combinations = movies['genres'].value_counts().head(15)\n",
    "for i, (combo, count) in enumerate(genre_combinations.items(), 1):\n",
    "    print(f\"   {i:2d}. {combo:50s} ({count:>4,} movies)\")\n",
    "\n",
    "print(\"\\n💡 Genre Co-occurrence Analysis:\")\n",
    "genre_pairs = Counter()\n",
    "for genres_list in movies['genres_list'].dropna():\n",
    "    if len(genres_list) >= 2:\n",
    "        for i in range(len(genres_list)):\n",
    "            for j in range(i + 1, len(genres_list)):\n",
    "                pair = tuple(sorted([genres_list[i], genres_list[j]]))\n",
    "                genre_pairs[pair] += 1\n",
    "\n",
    "print(\"\\n   Top 20 Genre Pairs:\")\n",
    "for i, (pair, count) in enumerate(genre_pairs.most_common(20), 1):\n",
    "    print(f\"   {i:2d}. {pair[0]:15s} + {pair[1]:15s} : {count:>5,} movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e1a402",
   "metadata": {},
   "source": [
    "## 7- MATRIX SPARSITY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e54fe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🔍 MATRIX SPARSITY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "📊 User-Movie Interaction Matrix:\n",
      "   • Dimensions:        162,541 users × 59,047 movies\n",
      "   • Total cells:           9,597,558,427\n",
      "   • Filled cells:             25,000,095\n",
      "   • Empty cells:           9,572,558,332\n",
      "   • Sparsity:                  99.739516%\n",
      "   • Density:                    0.260484%\n",
      "\n",
      "📉 Visual Representation:\n",
      "   Filled: [░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 0.260484%\n",
      "   Empty:  [████████████████████████████████████████] 99.739516%\n",
      "\n",
      "💡 What Sparsity Means:\n",
      "   ⚠️  VERY SPARSE matrix (99.7395%)\n",
      "   • Out of every 1,000 cells, only 2 are filled\n",
      "\n",
      "🎯 Why This Matters:\n",
      "   • Each user has rated 153.8 movies on average\n",
      "   • But there are 59,047 total movies\n",
      "   • Users have rated only 0.260% of all movies\n",
      "   • This creates the \"Cold Start\" problem\n",
      "\n",
      "📊 Coverage Analysis:\n",
      "\n",
      "   Movies Coverage:\n",
      "   • Movies with 1-10 ratings:      35,690 ( 60.4%)\n",
      "   • Movies with 11-50 ratings:     10,270 ( 17.4%)\n",
      "   • Movies with 51-100 ratings:     2,796 (  4.7%)\n",
      "   • Movies with 100+ ratings:      10,291 ( 17.4%)\n",
      "\n",
      "   Users Coverage:\n",
      "   • Users with 1-20 ratings:        4,611 (  2.8%)\n",
      "   • Users with 21-50 ratings:      56,856 ( 35.0%)\n",
      "   • Users with 51-100 ratings:     37,972 ( 23.4%)\n",
      "   • Users with 100+ ratings:       63,102 ( 38.8%)\n",
      "\n",
      "💡 Interpretation:\n",
      "   ⚠️  Matrix is 99.74% sparse\n",
      "   → Collaborative filtering alone will struggle\n",
      "   → Matrix factorization (SVD) is ESSENTIAL\n",
      "   → Content-based (genres + tags NLP) handles cold-start\n",
      "   → Hybrid approach combines strengths of all methods\n",
      "\n",
      "🎯 Recommendation Strategy:\n",
      "   1. Content-Based: Use genres + NLP on tags (handles cold-start)\n",
      "   2. Collaborative: User-user & item-item similarity\n",
      "   3. Matrix Factorization: SVD to handle sparsity\n",
      "   4. Hybrid: Combine all three for best results\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🔍 MATRIX SPARSITY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "matrix_size = n_users * n_movies\n",
    "sparsity = (1 - n_ratings / matrix_size) * 100\n",
    "\n",
    "print(f\"\\n📊 User-Movie Interaction Matrix:\")\n",
    "print(f\"   • Dimensions:     {n_users:>10,} users × {n_movies:>6,} movies\")\n",
    "print(f\"   • Total cells:    {matrix_size:>20,}\")\n",
    "print(f\"   • Filled cells:   {n_ratings:>20,}\")\n",
    "print(f\"   • Empty cells:    {matrix_size - n_ratings:>20,}\")\n",
    "print(f\"   • Sparsity:       {sparsity:>20.6f}%\")\n",
    "print(f\"   • Density:        {100-sparsity:>20.6f}%\")\n",
    "\n",
    "print(\"\\n📉 Visual Representation:\")\n",
    "filled = int((100 - sparsity) * 40 / 100)\n",
    "empty = 40 - filled\n",
    "print(f\"   Filled: [{'█' * filled}{'░' * empty}] {100-sparsity:.6f}%\")\n",
    "print(f\"   Empty:  [{'░' * filled}{'█' * empty}] {sparsity:.6f}%\")\n",
    "\n",
    "print(f\"\\n💡 What Sparsity Means:\")\n",
    "if sparsity > 99.9:\n",
    "    print(f\"   ⚠️  EXTREMELY SPARSE matrix ({sparsity:.4f}%)\")\n",
    "    print(f\"   • Out of every 10,000 cells, only {int((100-sparsity)*100):.0f} are filled\")\n",
    "    print(f\"   • Most user-movie pairs have NO interaction\")\n",
    "elif sparsity > 99:\n",
    "    print(f\"   ⚠️  VERY SPARSE matrix ({sparsity:.4f}%)\")\n",
    "    print(f\"   • Out of every 1,000 cells, only {int((100-sparsity)*10):.0f} are filled\")\n",
    "else:\n",
    "    print(f\"   ✅ Reasonable sparsity for collaborative filtering\")\n",
    "\n",
    "print(f\"\\n🎯 Why This Matters:\")\n",
    "print(f\"   • Each user has rated {n_ratings/n_users:.1f} movies on average\")\n",
    "print(f\"   • But there are {n_movies:,} total movies\")\n",
    "print(f\"   • Users have rated only {(n_ratings/n_users)/n_movies*100:.3f}% of all movies\")\n",
    "print(f\"   • This creates the \\\"Cold Start\\\" problem\")\n",
    "\n",
    "print(f\"\\n📊 Coverage Analysis:\")\n",
    "users_per_movie = ratings.groupby('movieId').size()\n",
    "movies_per_user = ratings.groupby('userId').size()\n",
    "\n",
    "print(f\"\\n   Movies Coverage:\")\n",
    "print(f\"   • Movies with 1-10 ratings:    {(users_per_movie <= 10).sum():>8,} ({(users_per_movie <= 10).sum()/n_movies*100:>5.1f}%)\")\n",
    "print(f\"   • Movies with 11-50 ratings:   {((users_per_movie > 10) & (users_per_movie <= 50)).sum():>8,} ({((users_per_movie > 10) & (users_per_movie <= 50)).sum()/n_movies*100:>5.1f}%)\")\n",
    "print(f\"   • Movies with 51-100 ratings:  {((users_per_movie > 50) & (users_per_movie <= 100)).sum():>8,} ({((users_per_movie > 50) & (users_per_movie <= 100)).sum()/n_movies*100:>5.1f}%)\")\n",
    "print(f\"   • Movies with 100+ ratings:    {(users_per_movie > 100).sum():>8,} ({(users_per_movie > 100).sum()/n_movies*100:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\n   Users Coverage:\")\n",
    "print(f\"   • Users with 1-20 ratings:     {(movies_per_user <= 20).sum():>8,} ({(movies_per_user <= 20).sum()/n_users*100:>5.1f}%)\")\n",
    "print(f\"   • Users with 21-50 ratings:    {((movies_per_user > 20) & (movies_per_user <= 50)).sum():>8,} ({((movies_per_user > 20) & (movies_per_user <= 50)).sum()/n_users*100:>5.1f}%)\")\n",
    "print(f\"   • Users with 51-100 ratings:   {((movies_per_user > 50) & (movies_per_user <= 100)).sum():>8,} ({((movies_per_user > 50) & (movies_per_user <= 100)).sum()/n_users*100:>5.1f}%)\")\n",
    "print(f\"   • Users with 100+ ratings:     {(movies_per_user > 100).sum():>8,} ({(movies_per_user > 100).sum()/n_users*100:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\n💡 Interpretation:\")\n",
    "print(f\"   ⚠️  Matrix is {sparsity:.2f}% sparse\")\n",
    "print(f\"   → Collaborative filtering alone will struggle\")\n",
    "print(f\"   → Matrix factorization (SVD) is ESSENTIAL\")\n",
    "print(f\"   → Content-based (genres + tags NLP) handles cold-start\")\n",
    "print(f\"   → Hybrid approach combines strengths of all methods\")\n",
    "\n",
    "print(f\"\\n🎯 Recommendation Strategy:\")\n",
    "print(f\"   1. Content-Based: Use genres + NLP on tags (handles cold-start)\")\n",
    "print(f\"   2. Collaborative: User-user & item-item similarity\")\n",
    "print(f\"   3. Matrix Factorization: SVD to handle sparsity\")\n",
    "print(f\"   4. Hybrid: Combine all three for best results\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d06c4b1",
   "metadata": {},
   "source": [
    "## 8- TEMPORAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b16dfa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "⏰ TEMPORAL ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "📅 Time Range:\n",
      "   • First rating:  1995-01-09 11:46:49\n",
      "   • Last rating:   2019-11-21 09:15:03\n",
      "   • Time span:     9,081 days\n",
      "   • Years covered: 25\n",
      "\n",
      "📊 Ratings by Year:\n",
      "   1995:                                                     0.00% (         3)\n",
      "   1996: ████████████████████████████                        5.72% ( 1,430,093)\n",
      "   1997: ████████████                                        2.50% (   626,202)\n",
      "   1998: █████                                               1.09% (   272,099)\n",
      "   1999: █████████████████████                               4.24% ( 1,059,080)\n",
      "   2000: ██████████████████████████████████                  6.94% ( 1,735,398)\n",
      "   2001: █████████████████████                               4.23% ( 1,058,750)\n",
      "   2002: ███████████████                                     3.11% (   776,654)\n",
      "   2003: ██████████████████                                  3.68% (   920,295)\n",
      "   2004: ████████████████████                                4.19% ( 1,048,116)\n",
      "   2005: ████████████████████████████████                    6.45% ( 1,613,550)\n",
      "   2006: ████████████████████                                4.15% ( 1,038,458)\n",
      "   2007: ██████████████████                                  3.73% (   931,432)\n",
      "   2008: ████████████████████                                4.07% ( 1,018,001)\n",
      "   2009: ████████████████                                    3.24% (   810,127)\n",
      "   2010: ███████████████                                     3.17% (   792,436)\n",
      "   2011: █████████████                                       2.71% (   676,498)\n",
      "   2012: ████████████                                        2.54% (   635,208)\n",
      "   2013: ██████████                                          2.06% (   515,684)\n",
      "   2014: █████████                                           1.91% (   478,270)\n",
      "   2015: ████████████████████████████████                    6.42% ( 1,604,971)\n",
      "   2016: ███████████████████████████████████                 7.03% ( 1,757,440)\n",
      "   2017: █████████████████████████████████                   6.76% ( 1,689,935)\n",
      "   2018: ██████████████████████████                          5.24% ( 1,310,761)\n",
      "   2019: ████████████████████████                            4.80% ( 1,200,634)\n",
      "\n",
      "📈 Most Active Years:\n",
      "    1. 2016:  1,757,440 ratings\n",
      "    2. 2000:  1,735,398 ratings\n",
      "    3. 2017:  1,689,935 ratings\n",
      "    4. 2005:  1,613,550 ratings\n",
      "    5. 2015:  1,604,971 ratings\n",
      "    6. 1996:  1,430,093 ratings\n",
      "    7. 2018:  1,310,761 ratings\n",
      "    8. 2019:  1,200,634 ratings\n",
      "    9. 1999:  1,059,080 ratings\n",
      "   10. 2001:  1,058,750 ratings\n",
      "\n",
      "📊 Ratings by Month:\n",
      "   Jan: ██████████████████████████      8.86% ( 2,213,815)\n",
      "   Feb: ██████████████████████          7.41% ( 1,852,220)\n",
      "   Mar: █████████████████████████       8.55% ( 2,138,362)\n",
      "   Apr: ███████████████████████         7.68% ( 1,921,173)\n",
      "   May: ████████████████████████        8.06% ( 2,015,370)\n",
      "   Jun: ███████████████████████         7.92% ( 1,980,125)\n",
      "   Jul: ██████████████████████████      8.73% ( 2,181,773)\n",
      "   Aug: ████████████████████████        8.26% ( 2,065,960)\n",
      "   Sep: █████████████████████           7.18% ( 1,795,639)\n",
      "   Oct: █████████████████████████       8.59% ( 2,146,844)\n",
      "   Nov: █████████████████████████████   9.78% ( 2,445,400)\n",
      "   Dec: ██████████████████████████      8.97% ( 2,243,414)\n",
      "\n",
      "📊 Ratings by Day of Week:\n",
      "   Monday   : ██████████████████████████████████████████████ 15.37% ( 3,841,946)\n",
      "   Tuesday  : ████████████████████████████████████████████ 14.85% ( 3,711,434)\n",
      "   Wednesday: █████████████████████████████████████████ 13.84% ( 3,459,648)\n",
      "   Thursday : ███████████████████████████████████████ 13.08% ( 3,269,846)\n",
      "   Friday   : ████████████████████████████████████████ 13.48% ( 3,370,458)\n",
      "   Saturday : █████████████████████████████████████████ 13.88% ( 3,470,070)\n",
      "   Sunday   : ██████████████████████████████████████████████ 15.51% ( 3,876,693)\n",
      "\n",
      "📊 Ratings by Hour of Day:\n",
      "    0:00: █████████                       4.71% ( 1,178,186)\n",
      "    1:00: ████████                        4.46% ( 1,115,989)\n",
      "    2:00: ████████                        4.45% ( 1,112,536)\n",
      "    3:00: ████████                        4.27% ( 1,068,687)\n",
      "    4:00: ███████                         3.74% (   933,822)\n",
      "    5:00: ██████                          3.38% (   844,382)\n",
      "    6:00: ██████                          3.07% (   767,792)\n",
      "    7:00: █████                           2.87% (   716,425)\n",
      "    8:00: █████                           2.71% (   677,941)\n",
      "    9:00: █████                           2.59% (   647,441)\n",
      "   10:00: █████                           2.66% (   664,241)\n",
      "   11:00: █████                           2.80% (   700,201)\n",
      "   12:00: ██████                          3.08% (   770,231)\n",
      "   13:00: ██████                          3.45% (   863,394)\n",
      "   14:00: ███████                         3.89% (   972,399)\n",
      "   15:00: ████████                        4.42% ( 1,106,172)\n",
      "   16:00: █████████                       4.74% ( 1,183,803)\n",
      "   17:00: ██████████                      5.09% ( 1,272,438)\n",
      "   18:00: ███████████                     5.56% ( 1,390,469)\n",
      "   19:00: ███████████                     5.85% ( 1,463,082)\n",
      "   20:00: ███████████                     5.87% ( 1,468,603)\n",
      "   21:00: ███████████                     5.94% ( 1,485,061)\n",
      "   22:00: ██████████                      5.45% ( 1,362,826)\n",
      "   23:00: █████████                       4.94% ( 1,233,974)\n",
      "\n",
      "💡 Temporal Insights:\n",
      "   • Peak year:        2016 (1,757,440 ratings)\n",
      "   • Peak month:       Nov (2,445,400 ratings)\n",
      "   • Peak day:         Sunday (3,876,693 ratings)\n",
      "   • Peak hour:        21:00 (1,485,061 ratings)\n",
      "\n",
      "📈 Rating Trends Over Time:\n",
      "   Average rating by year:\n",
      "   1995: ★★★ 3.67\n",
      "   1996: ★★★ 3.55\n",
      "   1997: ★★★ 3.59\n",
      "   1998: ★★★ 3.51\n",
      "   1999: ★★★ 3.62\n",
      "   2000: ★★★ 3.58\n",
      "   2001: ★★★ 3.53\n",
      "   2002: ★★★ 3.49\n",
      "   2003: ★★★ 3.48\n",
      "   2004: ★★★ 3.43\n",
      "   2005: ★★★ 3.43\n",
      "   2006: ★★★ 3.47\n",
      "   2007: ★★★ 3.47\n",
      "   2008: ★★★ 3.54\n",
      "   2009: ★★★ 3.51\n",
      "   2010: ★★★ 3.53\n",
      "   2011: ★★★ 3.55\n",
      "   2012: ★★★ 3.61\n",
      "   2013: ★★★ 3.65\n",
      "   2014: ★★★ 3.61\n",
      "   2015: ★★★ 3.56\n",
      "   2016: ★★★ 3.53\n",
      "   2017: ★★★ 3.55\n",
      "   2018: ★★★ 3.56\n",
      "   2019: ★★★ 3.58\n",
      "\n",
      "💡 Observations:\n",
      "   • Most ratings occurred in 2016\n",
      "   • Users rate most on Sundays\n",
      "   • Peak activity at 21:00 (likely evening)\n",
      "   • Dataset spans 25 years of user behavior\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"⏰ TEMPORAL ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "ratings['datetime'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "ratings['year'] = ratings['datetime'].dt.year\n",
    "ratings['month'] = ratings['datetime'].dt.month\n",
    "ratings['day_of_week'] = ratings['datetime'].dt.day_name()\n",
    "ratings['hour'] = ratings['datetime'].dt.hour\n",
    "\n",
    "print(f\"\\n📅 Time Range:\")\n",
    "print(f\"   • First rating:  {ratings['datetime'].min()}\")\n",
    "print(f\"   • Last rating:   {ratings['datetime'].max()}\")\n",
    "print(f\"   • Time span:     {(ratings['datetime'].max() - ratings['datetime'].min()).days:,} days\")\n",
    "print(f\"   • Years covered: {ratings['year'].max() - ratings['year'].min() + 1}\")\n",
    "\n",
    "print(f\"\\n📊 Ratings by Year:\")\n",
    "yearly = ratings.groupby('year').size().sort_index()\n",
    "for year in yearly.index:\n",
    "    count = yearly[year]\n",
    "    percentage = (count / n_ratings) * 100\n",
    "    bar_length = int(percentage * 5)\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"   {year}: {bar:<50} {percentage:5.2f}% ({count:>10,})\")\n",
    "\n",
    "print(f\"\\n📈 Most Active Years:\")\n",
    "top_years = yearly.sort_values(ascending=False).head(10)\n",
    "for i, (year, count) in enumerate(top_years.items(), 1):\n",
    "    print(f\"   {i:2d}. {year}: {count:>10,} ratings\")\n",
    "\n",
    "print(f\"\\n📊 Ratings by Month:\")\n",
    "monthly = ratings.groupby('month').size().sort_index()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "for month in monthly.index:\n",
    "    count = monthly[month]\n",
    "    percentage = (count / n_ratings) * 100\n",
    "    bar_length = int(percentage * 3)\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"   {month_names[month-1]:3s}: {bar:<30} {percentage:5.2f}% ({count:>10,})\")\n",
    "\n",
    "print(f\"\\n📊 Ratings by Day of Week:\")\n",
    "dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_counts = ratings['day_of_week'].value_counts()\n",
    "for day in dow_order:\n",
    "    count = dow_counts[day]\n",
    "    percentage = (count / n_ratings) * 100\n",
    "    bar_length = int(percentage * 3)\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"   {day:9s}: {bar:<30} {percentage:5.2f}% ({count:>10,})\")\n",
    "\n",
    "print(f\"\\n📊 Ratings by Hour of Day:\")\n",
    "hourly = ratings.groupby('hour').size().sort_index()\n",
    "for hour in hourly.index:\n",
    "    count = hourly[hour]\n",
    "    percentage = (count / n_ratings) * 100\n",
    "    bar_length = int(percentage * 2)\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"   {hour:2d}:00: {bar:<30} {percentage:5.2f}% ({count:>10,})\")\n",
    "\n",
    "print(f\"\\n💡 Temporal Insights:\")\n",
    "peak_year = yearly.idxmax()\n",
    "peak_month = monthly.idxmax()\n",
    "peak_dow = dow_counts.idxmax()\n",
    "peak_hour = hourly.idxmax()\n",
    "\n",
    "print(f\"   • Peak year:        {peak_year} ({yearly[peak_year]:,} ratings)\")\n",
    "print(f\"   • Peak month:       {month_names[peak_month-1]} ({monthly[peak_month]:,} ratings)\")\n",
    "print(f\"   • Peak day:         {peak_dow} ({dow_counts[peak_dow]:,} ratings)\")\n",
    "print(f\"   • Peak hour:        {peak_hour}:00 ({hourly[peak_hour]:,} ratings)\")\n",
    "\n",
    "print(f\"\\n📈 Rating Trends Over Time:\")\n",
    "yearly_avg_rating = ratings.groupby('year')['rating'].mean()\n",
    "print(f\"   Average rating by year:\")\n",
    "for year in yearly_avg_rating.index:\n",
    "    avg_rating = yearly_avg_rating[year]\n",
    "    stars = '★' * int(avg_rating)\n",
    "    print(f\"   {year}: {stars} {avg_rating:.2f}\")\n",
    "\n",
    "print(f\"\\n💡 Observations:\")\n",
    "print(f\"   • Most ratings occurred in {peak_year}\")\n",
    "print(f\"   • Users rate most on {peak_dow}s\")\n",
    "print(f\"   • Peak activity at {peak_hour}:00 (likely evening)\")\n",
    "print(f\"   • Dataset spans {ratings['year'].max() - ratings['year'].min() + 1} years of user behavior\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca75ae7",
   "metadata": {},
   "source": [
    "## 9- DATA QUALITY CHECK & SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9934109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "✅ DATA QUALITY CHECK\n",
      "================================================================================\n",
      "\n",
      "RATINGS Dataset:\n",
      "   • Total rows:                25,000,095\n",
      "   • Missing values:                     0\n",
      "   • Missing % :                    0.0000%\n",
      "   • Duplicate rows:                     0\n",
      "   • Memory usage:                 2577.38 MB\n",
      "\n",
      "   Column-wise missing values:\n",
      "      • userId              :          0 (✅ Complete)\n",
      "      • movieId             :          0 (✅ Complete)\n",
      "      • rating              :          0 (✅ Complete)\n",
      "      • timestamp           :          0 (✅ Complete)\n",
      "      • datetime            :          0 (✅ Complete)\n",
      "      • year                :          0 (✅ Complete)\n",
      "      • month               :          0 (✅ Complete)\n",
      "      • day_of_week         :          0 (✅ Complete)\n",
      "      • hour                :          0 (✅ Complete)\n",
      "\n",
      "   Additional checks:\n",
      "   • Invalid ratings (not 0.5-5.0):      0\n",
      "   • Negative IDs:                       0\n",
      "\n",
      "MOVIES Dataset:\n",
      "   • Total rows:                    62,423\n",
      "   • Missing values:                     0\n",
      "   • Missing % :                    0.0000%\n",
      "   • Duplicate rows:       Skipped (has list columns)\n",
      "   • Memory usage:                   18.09 MB\n",
      "\n",
      "   Column-wise missing values:\n",
      "      • movieId             :          0 (✅ Complete)\n",
      "      • title               :          0 (✅ Complete)\n",
      "      • genres              :          0 (✅ Complete)\n",
      "      • genres_list         :          0 (✅ Complete)\n",
      "      • genre_count         :          0 (✅ Complete)\n",
      "\n",
      "   Additional checks:\n",
      "   • Movies with no genres:       5,062 (8.11%)\n",
      "   • Duplicate movies:                0\n",
      "\n",
      "TAGS Dataset:\n",
      "   • Total rows:                 1,093,360\n",
      "   • Missing values:                    16\n",
      "   • Missing % :                    0.0004%\n",
      "   • Duplicate rows:                     0\n",
      "   • Memory usage:                   87.28 MB\n",
      "\n",
      "   Column-wise missing values:\n",
      "      • userId              :          0 (✅ Complete)\n",
      "      • movieId             :          0 (✅ Complete)\n",
      "      • tag                 :         16 (0.00%)\n",
      "      • timestamp           :          0 (✅ Complete)\n",
      "\n",
      "   Additional checks:\n",
      "   • Empty tags:                      9\n",
      "   • Very short tags (<2):          786 (0.07%)\n",
      "\n",
      "LINKS Dataset:\n",
      "   • Total rows:                    62,423\n",
      "   • Missing values:                   107\n",
      "   • Missing % :                    0.0571%\n",
      "   • Duplicate rows:                     0\n",
      "   • Memory usage:                    1.43 MB\n",
      "\n",
      "   Column-wise missing values:\n",
      "      • movieId             :          0 (✅ Complete)\n",
      "      • imdbId              :          0 (✅ Complete)\n",
      "      • tmdbId              :        107 (0.17%)\n",
      "\n",
      "================================================================================\n",
      "📊 DATASET SUMMARY\n",
      "================================================================================\n",
      "\n",
      "📋 Key Statistics:\n",
      "   • dataset_name                  :   MovieLens 25M\n",
      "   • collection_period             : 1995-01-09 11:46:49 to 2019-11-21 09:15:03\n",
      "   • total_ratings                 :      25,000,095\n",
      "   • unique_users                  :         162,541\n",
      "   • unique_movies                 :          59,047\n",
      "   • sparsity_percent              :           99.74\n",
      "   • avg_rating                    :            3.53\n",
      "   • median_rating                 :            3.50\n",
      "   • std_rating                    :            1.06\n",
      "   • unique_genres                 :              20\n",
      "   • total_tags                    :       1,093,360\n",
      "   • unique_tags                   :          73,050\n",
      "   • movies_with_tags              :          45,251\n",
      "   • movies_without_genres         :           5,062\n",
      "   • avg_ratings_per_user          :          153.81\n",
      "   • median_ratings_per_user       :           71.00\n",
      "   • avg_ratings_per_movie         :          423.39\n",
      "   • median_ratings_per_movie      :            6.00\n",
      "   • peak_year                     :           2,016\n",
      "   • peak_month                    :              11\n",
      "   • peak_day                      :          Sunday\n",
      "   • peak_hour                     :              21\n",
      "   • data_quality                  : Excellent - minimal missing values\n",
      "\n",
      "💾 Saving summary to file...\n",
      "✅ Summary saved to: c:\\Users\\mhfou\\Documents\\MovieRecommenderSystem\\data\\processed\\dataset_summary.json\n",
      "\n",
      "================================================================================\n",
      "✅ DATA LOADING & EXPLORATION COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "🎯 Key Findings:\n",
      "   • 25,000,095 ratings from 162,541 users on 59,047 movies\n",
      "   • Matrix is 99.74% sparse (challenging for CF)\n",
      "   • 20 genres for content-based filtering\n",
      "   • 73,050 unique tags for NLP analysis\n",
      "   • Average rating: 3.53/5.0 stars\n",
      "   • Data spans 25 years (1995-2019)\n",
      "   • Peak activity: Sundays at 21:00, in Nov, year 2016\n",
      "   • Data quality: EXCELLENT (minimal missing values)\n",
      "\n",
      "🚀 Next Steps:\n",
      "   ✅ Notebook 1: Data Loading & Exploration (COMPLETE)\n",
      "   📍 Notebook 2: Data Preprocessing & Feature Engineering\n",
      "   📍 Notebook 3: EDA & Visualizations\n",
      "   📍 Notebook 4: Content-Based Recommender (Genres + NLP)\n",
      "   📍 Notebook 5: Collaborative Filtering\n",
      "   📍 Notebook 6: Matrix Factorization (SVD)\n",
      "   📍 Notebook 7: Hybrid Model & Evaluation\n",
      "\n",
      "💡 Ready to proceed with preprocessing!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 10: DATA QUALITY CHECK & SUMMARY\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ DATA QUALITY CHECK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def check_quality(df, name, skip_duplicates=False):\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"   • Total rows:           {len(df):>15,}\")\n",
    "    print(f\"   • Missing values:       {df.isnull().sum().sum():>15,}\")\n",
    "    print(f\"   • Missing % :           {(df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100):>15.4f}%\")\n",
    "    \n",
    "    if not skip_duplicates:\n",
    "        print(f\"   • Duplicate rows:       {df.duplicated().sum():>15,}\")\n",
    "    else:\n",
    "        print(f\"   • Duplicate rows:       {'Skipped (has list columns)':>15}\")\n",
    "    \n",
    "    print(f\"   • Memory usage:         {df.memory_usage(deep=True).sum() / 1024**2:>15.2f} MB\")\n",
    "    \n",
    "    print(f\"\\n   Column-wise missing values:\")\n",
    "    for col in df.columns:\n",
    "        missing = df[col].isnull().sum()\n",
    "        if missing > 0:\n",
    "            print(f\"      • {col:20s}: {missing:>10,} ({missing/len(df)*100:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"      • {col:20s}: {missing:>10,} (✅ Complete)\")\n",
    "\n",
    "check_quality(ratings, \"RATINGS Dataset\")\n",
    "\n",
    "print(\"\\n   Additional checks:\")\n",
    "invalid_ratings = ((ratings['rating'] < 0.5) | (ratings['rating'] > 5.0)).sum()\n",
    "print(f\"   • Invalid ratings (not 0.5-5.0): {invalid_ratings:>6,}\")\n",
    "\n",
    "negative_ids = (ratings['userId'] < 0).sum() + (ratings['movieId'] < 0).sum()\n",
    "print(f\"   • Negative IDs:                  {negative_ids:>6,}\")\n",
    "\n",
    "check_quality(movies, \"MOVIES Dataset\", skip_duplicates=True)\n",
    "\n",
    "print(\"\\n   Additional checks:\")\n",
    "no_genre = (movies['genres'] == '(no genres listed)').sum()\n",
    "print(f\"   • Movies with no genres:  {no_genre:>10,} ({no_genre/len(movies)*100:.2f}%)\")\n",
    "\n",
    "movies_original_duplicates = movies[['movieId', 'title', 'genres']].duplicated().sum()\n",
    "print(f\"   • Duplicate movies:       {movies_original_duplicates:>10,}\")\n",
    "\n",
    "check_quality(tags, \"TAGS Dataset\")\n",
    "\n",
    "print(\"\\n   Additional checks:\")\n",
    "empty_tags = (tags['tag'].str.strip() == '').sum()\n",
    "print(f\"   • Empty tags:             {empty_tags:>10,}\")\n",
    "\n",
    "very_short_tags = (tags['tag'].str.len() < 2).sum()\n",
    "print(f\"   • Very short tags (<2):   {very_short_tags:>10,} ({very_short_tags/len(tags)*100:.2f}%)\")\n",
    "\n",
    "check_quality(links, \"LINKS Dataset\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📊 DATASET SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary = {\n",
    "    'dataset_name': 'MovieLens 25M',\n",
    "    'collection_period': f\"{ratings['datetime'].min()} to {ratings['datetime'].max()}\",\n",
    "    'total_ratings': int(n_ratings),\n",
    "    'unique_users': int(n_users),\n",
    "    'unique_movies': int(n_movies),\n",
    "    'sparsity_percent': float(sparsity),\n",
    "    'avg_rating': float(ratings['rating'].mean()),\n",
    "    'median_rating': float(ratings['rating'].median()),\n",
    "    'std_rating': float(ratings['rating'].std()),\n",
    "    'unique_genres': int(len(genre_counts)),\n",
    "    'total_tags': int(n_tags),\n",
    "    'unique_tags': int(n_unique_tags),\n",
    "    'movies_with_tags': int(n_movies_with_tags),\n",
    "    'movies_without_genres': int(no_genre),\n",
    "    'avg_ratings_per_user': float(user_counts.mean()),\n",
    "    'median_ratings_per_user': float(user_counts.median()),\n",
    "    'avg_ratings_per_movie': float(movie_counts.mean()),\n",
    "    'median_ratings_per_movie': float(movie_counts.median()),\n",
    "    'peak_year': int(peak_year),\n",
    "    'peak_month': int(peak_month),\n",
    "    'peak_day': peak_dow,\n",
    "    'peak_hour': int(peak_hour),\n",
    "    'data_quality': 'Excellent - minimal missing values'\n",
    "}\n",
    "\n",
    "print(\"\\n📋 Key Statistics:\")\n",
    "for key, value in summary.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"   • {key:30s}: {value:>15.2f}\")\n",
    "    elif isinstance(value, int):\n",
    "        print(f\"   • {key:30s}: {value:>15,}\")\n",
    "    else:\n",
    "        print(f\"   • {key:30s}: {value:>15}\")\n",
    "\n",
    "print(\"\\n💾 Saving summary to file...\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "summary_path = os.path.join(PROCESSED_DIR, 'dataset_summary.json')\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"✅ Summary saved to: {summary_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ DATA LOADING & EXPLORATION COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🎯 Key Findings:\")\n",
    "print(f\"   • {n_ratings:,} ratings from {n_users:,} users on {n_movies:,} movies\")\n",
    "print(f\"   • Matrix is {sparsity:.2f}% sparse (challenging for CF)\")\n",
    "print(f\"   • {len(genre_counts)} genres for content-based filtering\")\n",
    "print(f\"   • {n_unique_tags:,} unique tags for NLP analysis\")\n",
    "print(f\"   • Average rating: {ratings['rating'].mean():.2f}/5.0 stars\")\n",
    "print(f\"   • Data spans {ratings['year'].max() - ratings['year'].min() + 1} years ({ratings['year'].min()}-{ratings['year'].max()})\")\n",
    "print(f\"   • Peak activity: {peak_dow}s at {peak_hour}:00, in {month_names[peak_month-1]}, year {peak_year}\")\n",
    "print(f\"   • Data quality: EXCELLENT (minimal missing values)\")\n",
    "\n",
    "print(\"\\n🚀 Next Steps:\")\n",
    "print(\"   ✅ Notebook 1: Data Loading & Exploration (COMPLETE)\")\n",
    "print(\"   📍 Notebook 2: Data Preprocessing & Feature Engineering\")\n",
    "print(\"   📍 Notebook 3: EDA & Visualizations\")\n",
    "print(\"   📍 Notebook 4: Content-Based Recommender (Genres + NLP)\")\n",
    "print(\"   📍 Notebook 5: Collaborative Filtering\")\n",
    "print(\"   📍 Notebook 6: Matrix Factorization (SVD)\")\n",
    "print(\"   📍 Notebook 7: Hybrid Model & Evaluation\")\n",
    "\n",
    "print(\"\\n💡 Ready to proceed with preprocessing!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ac222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
