{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Data Preprocessing & Feature Engineering\n",
    "\n",
    "**Movie Recommendation System**  \n",
    "\n",
    "\n",
    "Clean data, engineer features, and prepare train/test splits for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 25,000,095 ratings, 62,423 movies, 1,093,360 tags\n"
     ]
    }
   ],
   "source": [
    "# Setup paths\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    BASE_DIR = os.path.dirname(os.getcwd())\n",
    "else:\n",
    "    BASE_DIR = os.getcwd()\n",
    "\n",
    "RAW_DIR = os.path.join(BASE_DIR, 'data', 'raw')\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Load datasets\n",
    "ratings = pd.read_csv(os.path.join(RAW_DIR, 'ratings.csv'))\n",
    "movies = pd.read_csv(os.path.join(RAW_DIR, 'movies.csv'))\n",
    "tags = pd.read_csv(os.path.join(RAW_DIR, 'tags.csv'))\n",
    "\n",
    "print(f\"Loaded: {len(ratings):,} ratings, {len(movies):,} movies, {len(tags):,} tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean Tags for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tags: 1093360\n",
      "Cleaned tags: 1,092,394\n",
      "Removed: 966 (0.1%)\n",
      "\n",
      "Top 10 tags:\n",
      "tag\n",
      "sci-fi                8795\n",
      "atmospheric           7053\n",
      "action                6783\n",
      "comedy                6370\n",
      "surreal               5584\n",
      "funny                 5366\n",
      "based on a book       5196\n",
      "twist ending          4904\n",
      "visually appealing    4691\n",
      "romance               4489\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Tag cleaning pipeline\n",
    "print(\"Original tags:\", len(tags))\n",
    "\n",
    "tags_clean = tags.dropna(subset=['tag']).copy()\n",
    "tags_clean['tag'] = tags_clean['tag'].str.lower().str.strip()\n",
    "tags_clean = tags_clean[tags_clean['tag'] != '']\n",
    "tags_clean = tags_clean[tags_clean['tag'].str.len() >= 2]\n",
    "tags_clean['tag'] = tags_clean['tag'].apply(lambda x: re.sub(r'[^a-z0-9\\s\\-]', '', x))\n",
    "tags_clean['tag'] = tags_clean['tag'].apply(lambda x: ' '.join(x.split()))\n",
    "tags_clean = tags_clean.drop_duplicates(subset=['userId', 'movieId', 'tag'])\n",
    "\n",
    "print(f\"Cleaned tags: {len(tags_clean):,}\")\n",
    "print(f\"Removed: {len(tags) - len(tags_clean):,} ({(len(tags) - len(tags_clean))/len(tags)*100:.1f}%)\")\n",
    "print(f\"\\nTop 10 tags:\")\n",
    "print(tags_clean['tag'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\mhfou\\Documents\\MovieRecommenderSystem\\data\\processed/tags_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned tags\n",
    "tags_clean.to_csv(os.path.join(PROCESSED_DIR, 'tags_clean.csv'), index=False)\n",
    "print(f\"Saved: {PROCESSED_DIR}/tags_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aggregate Tags per Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with tags: 45,249\n",
      "Avg tags per movie: 24.1\n",
      "Median: 5\n"
     ]
    }
   ],
   "source": [
    "# Aggregate tags by movie\n",
    "movie_tags = tags_clean.groupby('movieId')['tag'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "movie_tags.columns = ['movieId', 'tags_text']\n",
    "\n",
    "# Add tag statistics\n",
    "tag_counts = tags_clean.groupby('movieId').size().reset_index(name='tag_count')\n",
    "unique_tags = tags_clean.groupby('movieId')['tag'].nunique().reset_index(name='unique_tag_count')\n",
    "\n",
    "movie_tags = movie_tags.merge(tag_counts, on='movieId')\n",
    "movie_tags = movie_tags.merge(unique_tags, on='movieId')\n",
    "\n",
    "print(f\"Movies with tags: {len(movie_tags):,}\")\n",
    "print(f\"Avg tags per movie: {movie_tags['tag_count'].mean():.1f}\")\n",
    "print(f\"Median: {movie_tags['tag_count'].median():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\mhfou\\Documents\\MovieRecommenderSystem\\data\\processed/movie_tags_aggregated.csv\n"
     ]
    }
   ],
   "source": [
    "# Save aggregated tags\n",
    "movie_tags.to_csv(os.path.join(PROCESSED_DIR, 'movie_tags_aggregated.csv'), index=False)\n",
    "print(f\"Saved: {PROCESSED_DIR}/movie_tags_aggregated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process Movies & Engineer Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with year: 62,013\n"
     ]
    }
   ],
   "source": [
    "# Extract release year from title\n",
    "def extract_year(title):\n",
    "    match = re.search(r'\\((\\d{4})\\)', title)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "movies['release_year'] = movies['title'].apply(extract_year)\n",
    "\n",
    "print(f\"Movies with year: {movies['release_year'].notna().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with genres: 57,361\n"
     ]
    }
   ],
   "source": [
    "# Process genres\n",
    "movies['genres_list'] = movies['genres'].str.split('|')\n",
    "movies['genre_count'] = movies['genres_list'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "movies['has_genres'] = (movies['genres'] != '(no genres listed)').astype(int)\n",
    "\n",
    "print(f\"Movies with genres: {movies['has_genres'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with ratings: 59,047\n"
     ]
    }
   ],
   "source": [
    "# Calculate rating statistics per movie\n",
    "rating_stats = ratings.groupby('movieId').agg({\n",
    "    'rating': ['count', 'mean', 'std', 'min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "rating_stats.columns = ['movieId', 'rating_count', 'rating_mean', 'rating_std', 'rating_min', 'rating_max']\n",
    "rating_stats['rating_std'] = rating_stats['rating_std'].fillna(0)\n",
    "\n",
    "print(f\"Movies with ratings: {len(rating_stats):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal features calculated\n"
     ]
    }
   ],
   "source": [
    "# Calculate temporal features\n",
    "ratings['datetime'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "\n",
    "first_rating = ratings.groupby('movieId')['datetime'].min().reset_index()\n",
    "first_rating.columns = ['movieId', 'first_rating_date']\n",
    "\n",
    "last_rating = ratings.groupby('movieId')['datetime'].max().reset_index()\n",
    "last_rating.columns = ['movieId', 'last_rating_date']\n",
    "\n",
    "temporal_stats = first_rating.merge(last_rating, on='movieId')\n",
    "\n",
    "# Calculate age and activity span\n",
    "current_date = pd.Timestamp('2019-01-01')\n",
    "temporal_stats['movie_age_days'] = (current_date - temporal_stats['first_rating_date']).dt.days\n",
    "temporal_stats['activity_span_days'] = (temporal_stats['last_rating_date'] - temporal_stats['first_rating_date']).dt.days\n",
    "\n",
    "print(\"Temporal features calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final features shape: (62423, 21)\n",
      "Total features: 21 columns\n"
     ]
    }
   ],
   "source": [
    "# Merge all features\n",
    "movies_features = movies.copy()\n",
    "movies_features = movies_features.merge(rating_stats, on='movieId', how='left')\n",
    "movies_features = movies_features.merge(temporal_stats, on='movieId', how='left')\n",
    "movies_features = movies_features.merge(movie_tags[['movieId', 'tag_count', 'unique_tag_count']], on='movieId', how='left')\n",
    "\n",
    "# Fill missing values\n",
    "movies_features['rating_count'] = movies_features['rating_count'].fillna(0)\n",
    "movies_features['tag_count'] = movies_features['tag_count'].fillna(0)\n",
    "movies_features['has_tags'] = (movies_features['tag_count'] > 0).astype(int)\n",
    "\n",
    "# Calculate popularity score\n",
    "movies_features['popularity_score'] = np.log1p(movies_features['rating_count'])\n",
    "\n",
    "# Calculate rating velocity\n",
    "movies_features['rating_velocity'] = movies_features['rating_count'] / (movies_features['activity_span_days'] + 1)\n",
    "movies_features['rating_velocity'] = movies_features['rating_velocity'].fillna(0)\n",
    "\n",
    "print(f\"\\nFinal features shape: {movies_features.shape}\")\n",
    "print(f\"Total features: {movies_features.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\mhfou\\Documents\\MovieRecommenderSystem\\data\\processed/movies_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Save processed movies\n",
    "movies_features.to_csv(os.path.join(PROCESSED_DIR, 'movies_features.csv'), index=False)\n",
    "print(f\"Saved: {PROCESSED_DIR}/movies_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 20,000,076 ratings (80.0%)\n",
      "Test: 5,000,019 ratings (20.0%)\n",
      "\n",
      "Train date range: 1995-01-09 11:46:49 to 2016-06-25 06:49:57\n",
      "Test date range: 2016-06-25 06:50:00 to 2019-11-21 09:15:03\n"
     ]
    }
   ],
   "source": [
    "# Temporal split: 80% earliest ratings for training, 20% most recent for testing\n",
    "ratings_sorted = ratings.sort_values('timestamp')\n",
    "split_idx = int(len(ratings_sorted) * 0.8)\n",
    "\n",
    "train = ratings_sorted.iloc[:split_idx].copy()\n",
    "test = ratings_sorted.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"Train: {len(train):,} ratings ({len(train)/len(ratings)*100:.1f}%)\")\n",
    "print(f\"Test: {len(test):,} ratings ({len(test)/len(ratings)*100:.1f}%)\")\n",
    "print(f\"\\nTrain date range: {pd.to_datetime(train['timestamp'].min(), unit='s')} to {pd.to_datetime(train['timestamp'].max(), unit='s')}\")\n",
    "print(f\"Test date range: {pd.to_datetime(test['timestamp'].min(), unit='s')} to {pd.to_datetime(test['timestamp'].max(), unit='s')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cold-start analysis:\n",
      "Users only in test: 24,658 (79.4%)\n",
      "Movies only in test: 24,586 (44.5%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze cold-start problem\n",
    "train_users = set(train['userId'].unique())\n",
    "test_users = set(test['userId'].unique())\n",
    "train_movies = set(train['movieId'].unique())\n",
    "test_movies = set(test['movieId'].unique())\n",
    "\n",
    "cold_start_users = test_users - train_users\n",
    "cold_start_movies = test_movies - train_movies\n",
    "\n",
    "print(\"Cold-start analysis:\")\n",
    "print(f\"Users only in test: {len(cold_start_users):,} ({len(cold_start_users)/len(test_users)*100:.1f}%)\")\n",
    "print(f\"Movies only in test: {len(cold_start_movies):,} ({len(cold_start_movies)/len(test_movies)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train sparsity: 99.58%\n",
      "Test sparsity: 99.71%\n"
     ]
    }
   ],
   "source": [
    "# Calculate sparsity\n",
    "train_sparsity = (1 - len(train) / (train['userId'].nunique() * train['movieId'].nunique())) * 100\n",
    "test_sparsity = (1 - len(test) / (test['userId'].nunique() * test['movieId'].nunique())) * 100\n",
    "\n",
    "print(f\"\\nTrain sparsity: {train_sparsity:.2f}%\")\n",
    "print(f\"Test sparsity: {test_sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: c:\\Users\\mhfou\\Documents\\MovieRecommenderSystem\\data\\processed/train.csv\n",
      "Saved: c:\\Users\\mhfou\\Documents\\MovieRecommenderSystem\\data\\processed/test.csv\n"
     ]
    }
   ],
   "source": [
    "# Save train and test sets\n",
    "train[['userId', 'movieId', 'rating', 'timestamp']].to_csv(os.path.join(PROCESSED_DIR, 'train.csv'), index=False)\n",
    "test[['userId', 'movieId', 'rating', 'timestamp']].to_csv(os.path.join(PROCESSED_DIR, 'test.csv'), index=False)\n",
    "\n",
    "print(f\"\\nSaved: {PROCESSED_DIR}/train.csv\")\n",
    "print(f\"Saved: {PROCESSED_DIR}/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESSING COMPLETE\n",
      "\n",
      "Processed files:\n",
      "- tags_clean.csv: 1,092,394 cleaned tags\n",
      "- movie_tags_aggregated.csv: 45,249 movies with aggregated tags\n",
      "- movies_features.csv: 62,423 movies with 21 features\n",
      "- train_ratings.csv: 20,000,076 ratings (80%)\n",
      "- test_ratings.csv: 5,000,019 ratings (20%)\n",
      "\n",
      "Feature coverage:\n",
      "- Movies with genres: 57,361 (91.9%)\n",
      "- Movies with tags: 45,249 (72.5%)\n",
      "- Movies with ratings: 59,047 (94.6%)\n",
      "\n",
      "Cold-start scenarios:\n",
      "- Users in test only: 24,658\n",
      "- Movies in test only: 24,586\n",
      "\n",
      "Ready for:\n",
      "- Content-based filtering (genres + NLP)\n",
      "- Collaborative filtering\n",
      "- Matrix factorization (SVD)\n",
      "- Hybrid model\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "print(\"PREPROCESSING COMPLETE\")\n",
    "print(\"\\nProcessed files:\")\n",
    "print(f\"- tags_clean.csv: {len(tags_clean):,} cleaned tags\")\n",
    "print(f\"- movie_tags_aggregated.csv: {len(movie_tags):,} movies with aggregated tags\")\n",
    "print(f\"- movies_features.csv: {len(movies_features):,} movies with {movies_features.shape[1]} features\")\n",
    "print(f\"- train_ratings.csv: {len(train):,} ratings (80%)\")\n",
    "print(f\"- test_ratings.csv: {len(test):,} ratings (20%)\")\n",
    "\n",
    "print(\"\\nFeature coverage:\")\n",
    "print(f\"- Movies with genres: {movies_features['has_genres'].sum():,} ({movies_features['has_genres'].sum()/len(movies_features)*100:.1f}%)\")\n",
    "print(f\"- Movies with tags: {movies_features['has_tags'].sum():,} ({movies_features['has_tags'].sum()/len(movies_features)*100:.1f}%)\")\n",
    "print(f\"- Movies with ratings: {(movies_features['rating_count'] > 0).sum():,} ({(movies_features['rating_count'] > 0).sum()/len(movies_features)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nCold-start scenarios:\")\n",
    "print(f\"- Users in test only: {len(cold_start_users):,}\")\n",
    "print(f\"- Movies in test only: {len(cold_start_movies):,}\")\n",
    "\n",
    "print(\"\\nReady for:\")\n",
    "print(\"- Content-based filtering (genres + NLP)\")\n",
    "print(\"- Collaborative filtering\")\n",
    "print(\"- Matrix factorization (SVD)\")\n",
    "print(\"- Hybrid model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
